## æ¨é€ä»£ç åˆ° GitHub (Simplified)

```bash
# 1. æäº¤æœ¬åœ°æ›´æ”¹
git init
git add .
git commit -m "Update project"

# 2. è®¾ç½®è¿œç¨‹ä»“åº“å¹¶æ¨é€
git branch -M main
git remote remove origin 2>/dev/null || true
git remote add origin https://github.com/boboobooo-210/MCSkeleton.git
git push -u origin main
```

# CRSkeleton - GCN Skeleton Tokenizer

A PyTorch implementation of Graph Convolutional Network (GCN) based skeleton tokenizer for human action recognition.

## Features

- GCN-based skeleton tokenization
- Support for multiple datasets: NTU RGB+D, MARS, MMFI
- Memory-optimized training pipeline
- DVAE (Discrete Variational Autoencoder) integration

## Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/CRSkeleton.git
cd CRSkeleton
```

2. Install dependencies:
```bash
pip install torch torchvision torchaudio
pip install -r requirements.txt
```

## Usage

### Training

Train the GCN skeleton tokenizer with memory optimization:

```bash
# æ¿€æ´»condaç¯å¢ƒ
conda activate pb_final

# è®­ç»ƒï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ - é€‚ç”¨äº32GBå†…å­˜ï¼‰
python main.py --config cfgs/NTU_models/gcn_skeleton_memory_optimized.yaml
```

**å†…å­˜ä¼˜åŒ–ç‰¹æ€§:**
- âœ… æ‰¹å¤§å°ä¼˜åŒ–: 4 (é…åˆæ¢¯åº¦ç´¯ç§¯=2ï¼Œç­‰æ•ˆæ‰¹å¤§å°=8)
- âœ… åˆ†ç»„é‡æ„æŸå¤±: å¯¹æ¯ä¸ªè¯­ä¹‰ç»„å•ç‹¬è®¡ç®—æŸå¤±
- âœ… å…³èŠ‚æƒé‡ä¼˜åŒ–: å¤´éƒ¨ã€æ‰‹éƒ¨ã€è„šéƒ¨å…³èŠ‚æƒé‡Ã—2
- âœ… GPUå†…å­˜ç®¡ç†: è‡ªåŠ¨å†…å­˜æ¸…ç†å’Œä¼˜åŒ–åˆ†é…
- âœ… æ•°æ®åŠ è½½ä¼˜åŒ–: 2ä¸ªworkerè¿›ç¨‹ï¼Œå‡å°‘å†…å­˜å ç”¨

### Supported Datasets

- **NTU RGB+D**: Human action recognition dataset with skeleton data
- **MARS**: Multi-modal action recognition dataset
- **MMFI**: Multi-modal fitness dataset

### Configuration

Model configurations are stored in the `cfgs/` directory:
- `cfgs/NTU_models/` - NTU RGB+D dataset configurations
- `cfgs/MARS_models/` - MARS dataset configurations  
- `cfgs/MMFI_models/` - MMFI dataset configurations

## Project Structure

```
CRSkeleton/
â”œâ”€â”€ main.py                 # Main training script
â”œâ”€â”€ models/                 # Model implementations
â”‚   â”œâ”€â”€ GCNSkeletonTokenizer.py
â”‚   â”œâ”€â”€ Tokenizer.py
â”‚   â””â”€â”€ dvae.py
â”œâ”€â”€ datasets/              # Dataset implementations
â”œâ”€â”€ cfgs/                  # Configuration files
â”œâ”€â”€ tools/                 # Training utilities
â””â”€â”€ utils/                 # Common utilities
```

## Models

### GCNSkeletonTokenizer
- Graph Convolutional Network for skeleton feature extraction
- Tokenization of skeleton sequences
- Integration with DVAE for reconstruction

### DVAE (Discrete Variational Autoencoder)
- Discrete latent space representation
- Reconstruction loss optimization
- KL divergence regularization

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Based on PointNet++ PyTorch implementation
- Inspired by BERT tokenization mechanisms for skeleton data
# Pomelo

# CRSkeleton - GCN Skeleton Tokenizer

A PyTorch implementation of Graph Convolutional Network (GCN) based skeleton tokenizer for human action recognition.

## Features

- GCN-based skeleton tokenization
- Support for multiple datasets: NTU RGB+D, MARS, MMFI
- Memory-optimized training pipeline
- DVAE (Discrete Variational Autoencoder) integration

## Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/CRSkeleton.git
cd CRSkeleton
```

2. Install dependencies:
```bash
pip install torch torchvision torchaudio
pip install -r requirements.txt
```

## å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥ (Quick Reference Commands)

### 1. è®­ç»ƒ Context-Aware 10-Part æ¨¡å‹
```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate pb_final

# å¯åŠ¨è®­ç»ƒ
python main.py \
    --config cfgs/NTU_models/gcn_skeleton_context_aware_10p.yaml \
    --exp_name gcn_skeleton_context_aware_10p
```

### 2. ç”Ÿæˆè”åˆéƒ¨ä½æ ‡æ³¨ç´ æ (Joint Annotation GIFs)
ç”¨äºç”Ÿæˆ 360Â° æ—‹è½¬çš„è‚¢ä½“ç»„åˆ GIFï¼Œè¾…åŠ©äººå·¥æ ‡æ³¨ã€‚
```bash
python tools/generate_joint_annotation_gifs.py \
    --config cfgs/NTU_models/gcn_skeleton_context_aware_10p.yaml \
    --checkpoint experiments/gcn_skeleton_context_aware_10p/NTU_models/gcn_skeleton_context_aware_10p/ckpt-best.pth \
    --output_dir annotation_materials_joint \
    --max_batches -1
```

### 3. ç”Ÿæˆé‡æ„æ•ˆæœå¯¹æ¯” (Reconstruction Visualization)
éªŒè¯æ¨¡å‹çš„é‡æ„èƒ½åŠ›ï¼ˆç”Ÿæˆç›´ç«‹çš„éª¨æ¶å¯¹æ¯” GIFï¼‰ã€‚
```bash
python visualizations/gif_10p_final/generate_reconstruction_gifs.py
```

## å®Œæ•´é¡¹ç›®æ‰§è¡Œæµç¨‹ (Updated 2025.12)

### Phase 1: æ¨¡å‹è®­ç»ƒ (Model Training)

#### 1. è®­ç»ƒéª¨æ¶æå–æ¨¡å— (Skeleton Extractor)
**å½“å‰ç‰ˆæœ¬**: `Optimized MARS Model v2.0`
**è®­ç»ƒè„šæœ¬**: `models/skeleton_extractor_final.py`
```bash
python models/skeleton_extractor_final.py
```
**æ¨¡å‹ç‰¹ç‚¹**:
- æ¶æ„: SpatialPreservingBackbone + SimplifiedRegressionHead
- ä¼˜åŠ¿: æç®€è®¾è®¡ï¼Œè®­ç»ƒç¨³å®šï¼Œæ”¶æ•›å¿« (Val Loss ~0.017)
- **å¯è§†åŒ–éªŒè¯**: `visualizations/skeleton_extraction_final/vis_skeleton_extractor_final.py`
  - æ”¯æŒæ—¶åºå¹³æ»‘ (Temporal Smoothing) åå¤„ç†ï¼Œæ¶ˆé™¤æŠ–åŠ¨

#### 2. è®­ç»ƒéª¨æ¶é‡æ„æ¨¡å— (Skeleton Tokenizer)
**å½“å‰ç‰ˆæœ¬**: `10-Part GCN Tokenizer` (10éƒ¨ä½ç»†ç²’åº¦åˆ†è¯å™¨)
**è®­ç»ƒè„šæœ¬**: `main.py`
```bash
python main.py \
    --config cfgs/NTU_models/gcn_skeleton_context_aware_10p.yaml \
    --exp_name gcn_skeleton_context_aware_10p
```
**å˜æ›´è¯´æ˜**:
- ä»åŸå…ˆçš„ 5 è¯­ä¹‰ç»„å‡çº§ä¸º **10 è¯­ä¹‰ç»„** (10p)ï¼Œæä¾›æ›´ç»†ç²’åº¦çš„åŠ¨ä½œç¼–ç ã€‚
- **æ³¨æ„**: ä¹‹å‰çš„ 5p ç æœ¬å’Œæ ‡æ³¨å·²å¤±æ•ˆï¼Œéœ€é‡æ–°è¿›è¡Œåç»­æ­¥éª¤ã€‚

---

### Phase 2: æ•°æ®é›†å¤„ç†ä¸TokenåŒ– (Data Processing)

#### 3. è¿è¡Œæå–-é‡æ„æµæ°´çº¿ (Pipeline Demo)
**æµæ°´çº¿è„šæœ¬**: `tools/run_multi_group_pipeline.py`
```bash
python tools/run_multi_group_pipeline.py --mode 10p
```
**åŠŸèƒ½**: éªŒè¯ "è§†é¢‘ -> éª¨æ¶æå– -> 10p Tokenizer -> éª¨æ¶é‡æ„" çš„å®Œæ•´é“¾è·¯ã€‚
- ç¡®ä¿æå–çš„éª¨æ¶è´¨é‡ï¼ˆå·²é€šè¿‡æ—¶åºå¹³æ»‘ä¼˜åŒ–ï¼‰ã€‚
- ç¡®ä¿ 10p Tokenizer èƒ½æ­£ç¡®é‡æ„åŠ¨ä½œã€‚

#### 4. ç æœ¬ä½¿ç”¨ç‡åˆ†æ (Codebook Usage Analysis)
**è„šæœ¬**: 
- MARS (ç›®æ ‡åŸŸ): `tools/skeleton_extraction_reconstruction_saver.py` (éœ€æ›´æ–°é€‚é…10p)
- NTU (æºåŸŸ): `analyze_ntu_codebook_usage.py`

**ç›®æ ‡**: 
1. **MARSåˆ†æ**: ç»Ÿè®¡ç›®æ ‡æ•°æ®é›†ï¼ˆMARSï¼‰åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸Šçš„ç æœ¬æ¿€æ´»æƒ…å†µï¼Œè¯†åˆ«"ç æœ¬åå¡Œ"ï¼ˆCodebook Collapseï¼‰ç°è±¡ï¼ˆå¦‚ä»…ä½¿ç”¨ <10% çš„Tokenï¼‰ã€‚
2. **NTUåˆ†æ**: ç»Ÿè®¡æºæ•°æ®é›†ï¼ˆNTUï¼‰çš„ç æœ¬ä½¿ç”¨ç‡ä½œä¸ºåŸºå‡†ï¼ˆBaselineï¼‰ï¼Œç¡®è®¤æ¨¡å‹æœ¬èº«çš„è¡¨è¾¾èƒ½åŠ›ã€‚
3. **å¯¹æ¯”**: ç¡®å®šå“ªäº›Tokenæ˜¯é€šç”¨çš„ï¼ˆä¸¤è¾¹éƒ½é«˜é¢‘ï¼‰ï¼Œå“ªäº›æ˜¯ç‰¹å®šæ•°æ®é›†ç‹¬æœ‰çš„ã€‚

**æ‰§è¡Œå‘½ä»¤**:
```bash
# åˆ†æ MARS æ•°æ®é›†
python tools/skeleton_extraction_reconstruction_saver.py \
    --groups 10 \
    --model_path mars_optimized_best.pth

# åˆ†æ NTU æ•°æ®é›†
python analyze_ntu_codebook_usage.py \
    --config cfgs/NTU_models/gcn_skeleton_context_aware_10p.yaml \
    --checkpoint experiments/gcn_skeleton_context_aware_10p/NTU_models/gcn_skeleton_context_aware_10p/ckpt-best.pth
```

#### 5. [å…³é”®æ­¥éª¤] 10pç æœ¬è¯­ä¹‰æ ‡æ³¨ (Codebook Annotation)
**è„šæœ¬**: `tools/token_codebook_annotator.py` (æ ‡æ³¨å·¥å…·) / `tools/generate_annotation_gifs.py` (ç”Ÿæˆå¯è§†åŒ–ç´ æ)

**åˆ†æ”¯ç­–ç•¥**:
ç”±äº MARS æ•°æ®é›†åŠ¨ä½œå•ä¸€ï¼ˆä¸»è¦æ˜¯æ­¥è¡Œï¼‰ï¼Œè€Œ NTU æ•°æ®é›†åŠ¨ä½œä¸°å¯Œï¼Œæˆ‘ä»¬é‡‡ç”¨åŒåˆ†æ”¯æ ‡æ³¨ç­–ç•¥ï¼š

**åˆ†æ”¯ A: ç›®æ ‡åŸŸä¼˜å…ˆ (MARS Annotation)**
- **é€‚ç”¨åœºæ™¯**: ä»…å…³æ³¨ MARS æ•°æ®é›†ä¸­çš„ç‰¹å®šåŠ¨ä½œï¼ˆå¦‚è¡Œäººé‡è¯†åˆ«ã€æ­¥æ€åˆ†æï¼‰ã€‚
- **æ–¹æ³•**: ä»…æ ‡æ³¨ Step 4 ä¸­ MARS æ•°æ®é›†çš„é«˜é¢‘ Tokenï¼ˆé€šå¸¸ <100ä¸ªï¼‰ã€‚
- **ä¼˜ç‚¹**: å·¥ä½œé‡æå°ï¼Œå¿«é€Ÿå¯åŠ¨ã€‚
- **ç¼ºç‚¹**: æ— æ³•æ³›åŒ–åˆ°å…¶ä»–åŠ¨ä½œã€‚

**åˆ†æ”¯ B: æºåŸŸå…¨é¢æ ‡æ³¨ (NTU Annotation) - æ¨è**
- **é€‚ç”¨åœºæ™¯**: æ„å»ºé€šç”¨çš„éª¨æ¶åŠ¨ä½œç”Ÿæˆæ¨¡å‹ã€‚
- **ç­–ç•¥**: **è”åˆéƒ¨ä½æ ‡æ³¨ (Joint Limb Annotation)**ã€‚
- **åŸç†**: 10p æ¨¡å‹å°†å››è‚¢æ‹†åˆ†ä¸º Arm/Forearm å’Œ Leg/Footã€‚å•ç‹¬æ ‡æ³¨ Forearm å¾ˆéš¾åˆ¤æ–­åŠ¨ä½œï¼ˆå¦‚"å¼¯æ›²"å¯èƒ½æ˜¯ä¸¾æ‰‹ä¹Ÿå¯èƒ½æ˜¯æ•¬ç¤¼ï¼‰ã€‚å°†å®ƒä»¬ç»„åˆèµ·æ¥æ ‡æ³¨ï¼ˆArm+Forearmï¼‰èƒ½æ˜¾è‘—æå‡è¯­ä¹‰æ¸…æ™°åº¦ã€‚
- **å·¥ä½œé‡åˆ†æ**: 
    - ä¸‹è‚¢ï¼ˆLeg+Footï¼‰ï¼šç»„åˆæåº¦é›†ä¸­ï¼ŒTop 50 ç»„åˆè¦†ç›– 95% æ•°æ®ã€‚
    - ä¸Šè‚¢ï¼ˆArm+Forearmï¼‰ï¼šç»„åˆç›¸å¯¹åˆ†æ•£ï¼Œçº¦ 500-600 ç§æœ‰æ•ˆç»„åˆã€‚
    - **æ€»è®¡**: çº¦ 1200-1500 ä¸ªå¾…æ ‡æ³¨æ¡ç›®ï¼ˆè¿‡æ»¤æ‰æä½é¢‘å™ªå£°åï¼‰ã€‚
- **æ‰§è¡Œæ­¥éª¤**:
    1. **ç”Ÿæˆç´ æ**: è¿è¡Œ `tools/generate_joint_annotation_gifs.py`ã€‚è¯¥è„šæœ¬ä¼šè‡ªåŠ¨æ‰«æ NTU æ•°æ®é›†ï¼Œè¯†åˆ«æ‰€æœ‰å‡ºç°é¢‘ç‡ > 5 æ¬¡çš„è‚¢ä½“ Token ç»„åˆï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„ GIFã€‚
    2. **æ ‡æ³¨**: è§‚å¯Ÿç”Ÿæˆçš„ GIFï¼ˆæ–‡ä»¶ååŒ…å«é¢‘ç‡ä¿¡æ¯ï¼‰ï¼Œå¯¹ç»„åˆåŠ¨ä½œè¿›è¡Œæè¿°ï¼ˆä¾‹å¦‚ Left_Upper_Limb_TokenA_TokenB -> "å·¦æ‰‹-é«˜ä¸¾æŒ¥æ‰‹"ï¼‰ã€‚
    3. **è¾“å‡º**: `token_analysis/joint_codebook_annotations.json`

**æ‰§è¡Œæµç¨‹**:
1. **ç”Ÿæˆç´ æ**: 
   ```bash
   python tools/generate_joint_annotation_gifs.py \
       --config cfgs/NTU_models/gcn_skeleton_context_aware_10p.yaml \
       --checkpoint experiments/gcn_skeleton_context_aware_10p/NTU_models/gcn_skeleton_context_aware_10p/ckpt-best.pth \
       --output_dir annotation_materials_joint \
       --max_batches -1
   ```
2. **æ ‡æ³¨**: å‚è€ƒç”Ÿæˆçš„ GIF å½•å…¥è¯­ä¹‰æè¿°ã€‚

---

### Phase 3: LLM å¯¹æ¥ä¸è®­ç»ƒ (LLM Integration)

#### 6. æ„å»ºæŒ‡ä»¤å¾®è°ƒæ•°æ®é›† (Instruction Dataset Construction)
**ç›®æ ‡**: å°† Token åºåˆ—ä¸æ–‡æœ¬æè¿°é…å¯¹ã€‚
**æ•°æ®æ ¼å¼ç¤ºä¾‹**:
```json
{
  "instruction": "Generate a skeleton motion for 'walking forward'",
  "input": "",
  "output": "<group1_token_A> <group2_token_B> ... <group10_token_J> [Next Frame] ..."
}
```
**æ­¥éª¤**:
1. **æ¸…æ´—**: åŠ è½½ Step 4 ç”Ÿæˆçš„ `.npz` Token æ•°æ®ã€‚
2. **é…å¯¹**: åˆ©ç”¨ MARS æ•°æ®é›†çš„æ ‡ç­¾ï¼ˆLabelï¼‰æˆ–ä½¿ç”¨ VLM (å¦‚ Video-LLaMA) ç”Ÿæˆè§†é¢‘çš„æ–‡æœ¬æè¿°ã€‚
3. **æ ¼å¼åŒ–**: å°† `(Text, Token_Sequence)` è½¬æ¢ä¸º JSONL æ ¼å¼ï¼Œé€‚é… LLM è®­ç»ƒæ¡†æ¶ (å¦‚ LLaMA-Factory)ã€‚

#### 7. LLM è®­ç»ƒ (Training)
- **æ¨¡å‹é€‰æ‹©**: LLaMA-2-7B / Qwen-7B / TinyLlama (è§†ç®—åŠ›è€Œå®š)ã€‚
- **Tokenizeræ‰©å±•**: å°†éª¨æ¶ Token (å¦‚ `<s_0_123>`) åŠ å…¥ LLM çš„è¯è¡¨ï¼Œæˆ–ç›´æ¥ä½¿ç”¨æ•°å­—ç¼–ç ã€‚
- **è®­ç»ƒä»»åŠ¡**: Next Token Prediction (è‡ªå›å½’ç”Ÿæˆ)ã€‚

#### 8. æ¨ç†ä¸å¯è§†åŒ– (Inference)
- **è¾“å…¥**: æ–‡æœ¬æç¤º ("A person is waving hand")
- **è¾“å‡º**: é¢„æµ‹çš„ Token åºåˆ—
- **è§£ç **: Token åºåˆ— -> `10p GCN Decoder` -> éª¨æ¶åæ ‡ -> `vis_skeleton_extractor_final.py` (å¤ç”¨å¯è§†åŒ–é€»è¾‘) -> GIFåŠ¨ç”»
python tools/token_codebook_annotator.py
```
**è¾“å‡º**: `token_analysis/codebook_annotations.json`
- äººå·¥æ ‡æ³¨é«˜é¢‘tokençš„è¯­ä¹‰æè¿°
- è‡ªåŠ¨è¯»å– `token_schema.json` è¯†åˆ«è¯­ä¹‰ç»„ï¼ˆ10ç»„: head_neck, spine, left_arm, left_forearm, right_arm, right_forearm, left_leg, left_foot, right_leg, right_footï¼‰
- ç¤ºä¾‹: `{"head_neck": {"25": "ç‚¹å¤´"}, ...}`

---

### Phase 3: LLMé›†æˆä¸å¯¹é½

#### 6. è½¬æ¢Tokenå­—å…¸æ ¼å¼
**è½¬æ¢è„šæœ¬**: `llm_tools/build_token_dictionary.py`
```bash
# åŸºæœ¬è½¬æ¢ï¼ˆä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰
python llm_tools/build_token_dictionary.py

# æˆ–æŒ‡å®šè¾“å…¥è¾“å‡ºæ–‡ä»¶
python llm_tools/build_token_dictionary.py \
  --input token_analysis/codebook_annotations.json \
  --output llm_tools/token_dictionary.json

# éªŒè¯ç°æœ‰å­—å…¸æ ¼å¼
python llm_tools/build_token_dictionary.py --verify-only
```

**è½¬æ¢é€»è¾‘è¯¦è§£**:

è¾“å…¥æ ¼å¼ (`codebook_annotations.json`):
```json
{
  "codebook_annotation": {
    "head_spine": {
      "35": "å·¦å€¾æ–œ",
      "38": "å³å€¾æ–œ",
      "44": "æ­£å¸¸å§¿æ€ï¼ˆå¾®å¾®å·¦å€¾ï¼‰"
    },
    "left_arm": {
      "128": "å‘å†…å¼¯æ›²ï¼ˆèµ·èµ·æŠ¬èµ·æŠ¬èµ·ï¼‰",
      "143": "å‘å†…å¼¯æ›²ï¼ˆå‘å‰è‡ªç„¶æŠ¬èµ·ï¼‰"
    },
    ...
  },
  "metadata": {
    "total_unique_tokens": 54,
    "annotated_tokens": 54
  }
}
```

è¾“å‡ºæ ¼å¼ (`token_dictionary.json`):
```json
{
  "metadata": {
    "total_tokens": 96,
    "group_order": [
      "head_neck",
      "spine",
      "left_arm",
      "left_forearm",
      "right_arm",
      "right_forearm",
      "left_leg",
      "left_foot",
      "right_leg",
      "right_foot"
    ],
    "group_offsets": [0, 32, 64, 112, 160, 208, 256, 320, 384, 448],
    "group_token_sizes": [32, 32, 48, 48, 48, 48, 64, 64, 64, 64],
    "last_updated": "2025-11-06T15:02:41.508910",
    "source": "token_analysis/codebook_annotations.json"
  },
  "groups": {
    "head_neck": {
      "name": "å¤´é¢ˆ",
      "token_range": [0, 31],
      "annotated_tokens": 9,
      "token_ids": [5, 12, 18, ...]
    },
    "left_forearm": {
      "name": "å·¦å‰è‡‚ä¸æ‰‹",
      "token_range": [112, 159],
      "annotated_tokens": 11,
      "token_ids": [128, 133, 147, ...]
    },
    ...
  },
  "tokens": [
    {
      "id": 5,
      "group": "head_neck",
      "description": "å¾®å¾®æŠ¬å¤´",
      "frequency": 0
    },
    {
      "id": 128,
      "group": "left_forearm",
      "description": "æ‰‹æŒå‘å‰ä¼¸å±•",
      "frequency": 0
    },
    ...
  ]
}
```

**æ ¸å¿ƒè½¬æ¢æ­¥éª¤**:
1. **è¯»å–æºæ–‡ä»¶**: åŠ è½½ `codebook_annotation` ä¸­çš„åµŒå¥—å­—å…¸
2. **æ„å»ºgroupså…ƒæ•°æ®**: 
   - è¯»å– `metadata.group_order` ä¸ `group_offsets`
   - ç”Ÿæˆ `token_range = [offset, offset + size - 1]`
   - å†™å…¥è¯­ä¹‰ç»„æ˜¾ç¤ºåç§° (`group_display_names`)
   - ç»Ÿè®¡å·²æ ‡æ³¨tokenæ•°é‡ (`annotated_tokens`)
3. **æ‰å¹³åŒ–tokenåˆ—è¡¨**: å°†åµŒå¥—çš„å­—å…¸è½¬æ¢ä¸ºæ•°ç»„
   - æ¯ä¸ªtokenåŒ…å«: `id`, `group`, `description`, `frequency`
   - æŒ‰token IDæ’åºï¼Œæ–¹ä¾¿æŸ¥è¯¢
4. **éªŒè¯è¾“å‡º**: è‡ªåŠ¨æ£€æŸ¥æ ¼å¼å®Œæ•´æ€§å’Œæ•°æ®ä¸€è‡´æ€§

**è½¬æ¢ç›®çš„**:
- âœ… **æ‰å¹³åŒ–ç»“æ„**: æ–¹ä¾¿LLMå¿«é€ŸæŸ¥è¯¢ï¼ˆO(1)å¤æ‚åº¦ï¼‰
- âœ… **åŠ¨æ€å…ƒæ•°æ®**: è‡ªåŠ¨è®°å½• `group_order/group_offsets` ä»¥é€‚é…5ç»„æˆ–10ç»„Tokenizer
- âœ… **æ ‡å‡†åŒ–æ ¼å¼**: ç»Ÿä¸€çš„JSON schemaï¼Œæ˜“äºç»´æŠ¤
- âœ… **é¢„ç•™æ‰©å±•**: `frequency`å­—æ®µå¯åç»­ç»Ÿè®¡tokenä½¿ç”¨é¢‘ç‡

**æ³¨æ„äº‹é¡¹**:
- å¦‚æœä¿®æ”¹äº† `codebook_annotations.json` çš„æ ‡æ³¨ï¼Œéœ€è¦é‡æ–°è¿è¡Œè½¬æ¢è„šæœ¬
- è½¬æ¢è„šæœ¬ä¼šè‡ªåŠ¨éªŒè¯è¾“å‡ºæ ¼å¼çš„æ­£ç¡®æ€§
- ä¿æŒ `token_schema.json` ä¸æœ€æ–°æ¨¡å‹ä¸€è‡´ï¼ˆschema å˜æ›´åéœ€é‡æ–°å¯¼å‡º/æ ‡æ³¨ï¼‰
- è‹¥å­˜åœ¨è‡ªå®šä¹‰Tokenizerï¼Œè¯·ç¡®è®¤ `metadata.group_offsets` ä¸è®­ç»ƒé…ç½®åŒ¹é…

**è¯¦ç»†è½¬æ¢æ–‡æ¡£**: ğŸ“– `llm_tools/TOKEN_DICTIONARY_CONVERSION.md`

#### 7. é…ç½®LLM APIå¯†é’¥
**æ”¯æŒçš„å›½äº§LLM**: é€šä¹‰åƒé—®(æ¨è) / GLM-4 / DeepSeek
```bash
# è®¾ç½®é€šä¹‰åƒé—®API Key (æ¨è)
export DASHSCOPE_API_KEY='your-api-key-here'

# æˆ–è®¾ç½®æ™ºè°±AI
export ZHIPUAI_API_KEY='your-api-key-here'

# æˆ–è®¾ç½®DeepSeek
export DEEPSEEK_API_KEY='your-api-key-here'
```

**è·å–API Key**:
- é€šä¹‰åƒé—®: https://help.aliyun.com/zh/dashscope/
- æ™ºè°±AI: https://open.bigmodel.cn/
- DeepSeek: https://platform.deepseek.com/

#### 8. æµ‹è¯•LLMé›†æˆ
**æµ‹è¯•è„šæœ¬**: ä½¿ç”¨ `llm_tools/chinese_llm_integration.py`
```bash
# æµ‹è¯•å•ä¸ªæ ·æœ¬
python -c "
from llm_tools.chinese_llm_integration import SkeletonLLMAlignment

workflow = SkeletonLLMAlignment(
    llm_provider='qianwen',
    token_dict_path='llm_tools/token_dictionary.json',
    recon_data_dir='data/MARS_recon_tokens'
)

# æµ‹è¯•tokenåºåˆ—
result = workflow.process_single_sample([125, 252, 327, 489, 608])
print(f'Token: {result[\"token_sequence\"]}')
print(f'æè¿°: {result[\"llm_description\"]}')
print(f'è€—æ—¶: {result[\"processing_time\"]:.2f}ç§’')
"
```

**é¢„æœŸè¾“å‡º**:
```
Token: [125, 252, 327, 489, 608]
æè¿°: äººç‰©èº«ä½“ç¨å¾®å‘å·¦å€¾æ–œï¼ŒåŒè‡‚è‡ªç„¶å¼¯æ›²ä¸‹å‚ï¼ŒåŒè…¿ç›´ç«‹ç«™ç«‹ã€‚
è€—æ—¶: 0.87ç§’
```

#### 9. æ‰¹é‡å¤„ç†MARSæ•°æ®é›†
**æ‰¹é‡å¤„ç†è„šæœ¬**: `llm_tools/batch_process_all.py`
```bash
python llm_tools/batch_process_all.py
```

**äº¤äº’å¼é€‰é¡¹**:
1. å°æ‰¹é‡æµ‹è¯• (100ä¸ªæ ·æœ¬, ~2åˆ†é’Ÿ)
2. ä¸­æ‰¹é‡éªŒè¯ (500ä¸ªæ ·æœ¬, ~8åˆ†é’Ÿ)
3. å®Œæ•´å¤„ç† (7,984ä¸ªæ ·æœ¬, ~2å°æ—¶)

**è¾“å‡º**: `llm_tools/batch_XXX_aligned.json`
```json
[
  {
    "token_sequence": [125, 252, 327, 489, 608],
    "llm_description": "äººç‰©èº«ä½“ç¨å¾®å‘å·¦å€¾æ–œï¼ŒåŒè‡‚è‡ªç„¶å¼¯æ›²ä¸‹å‚ï¼ŒåŒè…¿ç›´ç«‹ç«™ç«‹ã€‚",
    "processing_time": 0.87
  },
  ...
]
```

#### 10. å¯è§†åŒ–éªŒè¯LLMæè¿°å‡†ç¡®æ€§
**å¯è§†åŒ–è„šæœ¬**: `visualizations/skeleton_extractor/vis_mars_recon_tokens.py`
```bash
# æŸ¥çœ‹æŒ‡å®šæ ·æœ¬çš„éª¨æ¶å¯è§†åŒ–
python visualizations/skeleton_extractor/vis_mars_recon_tokens.py --split test --index 1

# å åŠ æ¨¡å¼(åŸå§‹ vs é‡æ„)
python visualizations/skeleton_extractor/vis_mars_recon_tokens.py --split test --index 1 --overlay
```

**åŠŸèƒ½**:
- 3Déª¨æ¶å¯è§†åŒ– (åŸå§‹ vs åŸºç¡€é‡æ„ vs æœ€ç»ˆé‡æ„)
- æ˜¾ç¤ºtokenåºåˆ—å’ŒVQæŸå¤±
- æŒ‰5ä¸ªè¯­ä¹‰ç»„ç€è‰²
- è®¡ç®—é‡æ„è¯¯å·®

**éªŒè¯æµç¨‹**:
```
1. è¿è¡Œå¯è§†åŒ– â†’ äººçœ¼è§‚å¯Ÿéª¨æ¶å§¿æ€
2. æŸ¥çœ‹å¯¹åº”çš„LLMæè¿°
3. éªŒè¯æè¿°æ˜¯å¦å‡†ç¡®åŒ¹é…éª¨æ¶
4. å¦‚ä¸å‡†ç¡® â†’ è°ƒæ•´promptæˆ–è¡¥å……tokenæ ‡æ³¨
5. é‡æ–°è¿è¡ŒLLMå¤„ç†
```

---

### Phase 4: æ•°æ®é›†æ„å»º(å¯é€‰)

#### 11. ç”ŸæˆLLMå¾®è°ƒè®­ç»ƒæ•°æ®
**ç”Ÿæˆè„šæœ¬**: ä½¿ç”¨ `SkeletonLLMAlignment.create_token_llm_training_data()`
```bash
python -c "
from llm_tools.chinese_llm_integration import SkeletonLLMAlignment

workflow = SkeletonLLMAlignment(llm_provider='qianwen')
workflow.create_token_llm_training_data(
    num_samples=500,
    output_path='llm_tools/token_llm_training_data.jsonl'
)
"
```

**è¾“å‡ºæ ¼å¼** (JSONL):
```json
{"instruction": "è¯·æè¿°ä»¥ä¸‹éª¨æ¶å§¿æ€tokenä»£è¡¨çš„åŠ¨ä½œ", "input": "Tokenåºåˆ—: [125, 252, 327, 489, 608]", "output": "äººç‰©èº«ä½“ç¨å¾®å‘å·¦å€¾æ–œ..."}
{"instruction": "è¯·æè¿°ä»¥ä¸‹éª¨æ¶å§¿æ€tokenä»£è¡¨çš„åŠ¨ä½œ", "input": "Tokenåºåˆ—: [44, 218, 265, 489, 608]", "output": "äººç‰©ç›´ç«‹ç«™å§¿..."}
```

**ç”¨é€”**: å¾®è°ƒLLMä½¿å…¶ç›´æ¥ç†è§£tokenåºåˆ—ï¼Œæ— éœ€ç æœ¬æŸ¥è¯¢

---

## æ ¸å¿ƒæ–‡ä»¶æ¸…å• (Core File Inventory)

### 1. æ¨¡å‹å®šä¹‰ (Model Definitions)
- **éª¨æ¶æå–å™¨ (Skeleton Extractor)**: `models/skeleton_extractor_final.py`
  - ç”¨äºä»è§†é¢‘æˆ–åŸå§‹æ•°æ®ä¸­æå–é«˜è´¨é‡éª¨æ¶ã€‚
- **éª¨æ¶åˆ†è¯å™¨ (Skeleton Tokenizer)**: `models/GCNSkeletonTokenizer_10p.py`
  - **Context-Aware 10-Part** ç‰ˆæœ¬ï¼Œè´Ÿè´£å°†éª¨æ¶ç¼–ç ä¸ºç¦»æ•£ Token å¹¶é‡æ„ã€‚
  - åŒ…å« `SkeletonGraph` å®šä¹‰ï¼ˆ10ä¸ªè¯­ä¹‰ç»„ï¼‰å’Œ `ST_GCN_Layer`ã€‚

### 2. è®­ç»ƒè„šæœ¬ (Training Scripts)
- **è®­ç»ƒæå–å™¨**: `models/skeleton_extractor_final.py` (ç›´æ¥è¿è¡Œ)
- **è®­ç»ƒåˆ†è¯å™¨**: `main.py`
  - é…åˆé…ç½®æ–‡ä»¶: `cfgs/NTU_models/gcn_skeleton_context_aware_10p.yaml`

### 3. æ•°æ®å¤„ç†ä¸æµæ°´çº¿ (Pipeline & Data Processing)
- **å¤šç»„æµæ°´çº¿æ¼”ç¤º**: `tools/run_multi_group_pipeline.py`
  - éªŒè¯ "è¾“å…¥ -> æå– -> TokenåŒ– -> é‡æ„" çš„å®Œæ•´æµç¨‹ã€‚
  - æ ¸å¿ƒé€»è¾‘å®ç°: `tools/multi_group_skeleton_pipeline.py`
- **ç æœ¬ä½¿ç”¨ç‡åˆ†æ**: `analyze_ntu_codebook_usage.py`
  - ç»Ÿè®¡ NTU æ•°æ®é›†ä¸Šçš„ Token åˆ†å¸ƒï¼Œæ£€æµ‹ç æœ¬åå¡Œã€‚
- **MARS æ•°æ®é›†é‡æ„ä¿å­˜**: `tools/skeleton_extraction_reconstruction_saver.py`
  - å°† MARS æ•°æ®é›†å¤„ç†ä¸º Token åºåˆ—å¹¶ä¿å­˜ä¸º `.npz`ã€‚

### 4. æ ‡æ³¨ä¸å¯è§†åŒ–å·¥å…· (Annotation & Visualization)
- **è”åˆéƒ¨ä½æ ‡æ³¨ç´ æç”Ÿæˆ**: `tools/generate_joint_annotation_gifs.py`
  - **åŠŸèƒ½**: æ‰«ææ•°æ®é›†ï¼Œç”Ÿæˆè‚¢ä½“ç»„åˆï¼ˆå¦‚å·¦è‡‚+å·¦å‰è‡‚ï¼‰çš„ 360Â° æ—‹è½¬ GIFã€‚
  - **ç”¨é€”**: è¾…åŠ©äººå·¥è¿›è¡Œè¯­ä¹‰æ ‡æ³¨ã€‚
- **é‡æ„æ•ˆæœå¯è§†åŒ–**: `visualizations/gif_10p_final/generate_reconstruction_gifs.py`
  - **åŠŸèƒ½**: ç”Ÿæˆ "åŸå§‹éª¨æ¶ vs é‡æ„éª¨æ¶" çš„å¯¹æ¯” GIFã€‚
  - **ç‰¹ç‚¹**: ä¿®æ­£äº†åæ ‡ç³»ï¼ˆç›´ç«‹æ˜¾ç¤ºï¼‰ï¼Œæ”¯æŒ Context-Aware æ¨¡å‹çš„å­—å…¸è¾“å‡ºã€‚
- **æ ‡æ³¨å·¥å…·**: `tools/token_codebook_annotator.py`
  - ç”¨äºå½•å…¥å’Œç®¡ç† Token çš„è¯­ä¹‰æè¿°ã€‚

### 5. LLM é›†æˆ (LLM Integration)
- **Token å­—å…¸æ„å»º**: `llm_tools/build_token_dictionary.py`
  - å°†æ ‡æ³¨å¥½çš„ JSON è½¬æ¢ä¸º LLM å¯è¯»çš„å­—å…¸æ ¼å¼ã€‚
- **LLM å¯¹é½æ ¸å¿ƒ**: `llm_tools/chinese_llm_integration.py`
  - å®ç° "Token åºåˆ— -> è‡ªç„¶è¯­è¨€æè¿°" çš„è½¬æ¢é€»è¾‘ã€‚
- **æ‰¹é‡å¤„ç†**: `llm_tools/batch_process_all.py`

### 6. é…ç½®æ–‡ä»¶ (Configurations)
- **NTU 10-Part Context-Aware**: `cfgs/NTU_models/gcn_skeleton_context_aware_10p.yaml`
- **æ•°æ®é›†é…ç½®**: `cfgs/dataset_configs/NTU_skeleton_raw.yaml`

---

## æŠ€æœ¯æ¶æ„ï¼šç æœ¬-LLMå¯¹é½

### å¯¹é½åŸç†
```
éª¨æ¶(25,3) â†’ GCNç¼–ç  â†’ Tokenåºåˆ—[5ä¸ª] â†’ ç æœ¬æŸ¥è¯¢ â†’ è¯­ä¹‰æè¿° â†’ LLMç†è§£ â†’ è‡ªç„¶è¯­è¨€
```

### å…³é”®æœºåˆ¶
1. **ç æœ¬å»ºç«‹**: äººå·¥æ ‡æ³¨tokenè¯­ä¹‰ (54ä¸ªé«˜é¢‘tokenå·²æ ‡æ³¨)
2. **æŸ¥è¯¢æ˜ å°„**: Token ID â†’ è¯­ä¹‰æè¿° (å¦‚: 125 â†’ "å·¦å€¾æ–œ")
3. **Promptæ„å»º**: å°†è¯­ä¹‰æè¿°è½¬æ¢ä¸ºç»“æ„åŒ–prompt
4. **LLMç†è§£**: ç»¼åˆå„éƒ¨ä½æè¿°ï¼Œç”Ÿæˆå®Œæ•´åŠ¨ä½œæè¿°

### ç¤ºä¾‹æµç¨‹
```python
# Tokenåºåˆ—
[125, 252, 327, 489, 608]

# ç æœ¬æŸ¥è¯¢
head_spine: 125 â†’ "å·¦å€¾æ–œ"
left_arm: 252 â†’ "è‡ªç„¶å¼¯æ›²"
right_arm: 327 â†’ "è‡ªç„¶å¼¯æ›²"
left_leg: 489 â†’ "ç«™ç«‹ï¼ˆç›´ç«‹ï¼‰"
right_leg: 608 â†’ "ç«™ç«‹"

# LLMç”Ÿæˆ
"äººç‰©èº«ä½“ç¨å¾®å‘å·¦å€¾æ–œï¼ŒåŒè‡‚è‡ªç„¶å¼¯æ›²ä¸‹å‚ï¼ŒåŒè…¿ç›´ç«‹ç«™ç«‹ã€‚"
```

**å®Œæ•´æŠ€æœ¯æ–‡æ¡£**: ğŸ“– `llm_tools/CODEBOOK_LLM_ALIGNMENT.md`

---

## æˆæœ¬ä¼°ç®—

### LLMå¤„ç†æˆæœ¬ (é€šä¹‰åƒé—® qwen-turbo)
- å•æ ·æœ¬: ~250 tokens Ã— 0.008å…ƒ/åƒtokens = 0.002å…ƒ
- 100æ ·æœ¬: 0.2å…ƒ (~2åˆ†é’Ÿ)
- 7,984æ ·æœ¬(å…¨éƒ¨æµ‹è¯•é›†): ~16å…ƒ (~2å°æ—¶)
- **å…è´¹é¢åº¦**: 100ä¸‡tokens/æœˆ (è¶³å¤Ÿå¤„ç†40,086ä¸ªæ ·æœ¬)

---

## å¿«é€Ÿå¼€å§‹

### æœ€å°å¯è¡Œæµç¨‹
```bash
# 1. å‡è®¾æ¨¡å‹å·²è®­ç»ƒå®Œæˆ
# 2. é…ç½®APIå¯†é’¥
export DASHSCOPE_API_KEY='your-key'

# 3. æµ‹è¯•LLMé›†æˆ
python -c "from llm_tools.chinese_llm_integration import SkeletonLLMAlignment; \
           workflow = SkeletonLLMAlignment(llm_provider='qianwen'); \
           result = workflow.process_single_sample([125, 252, 327, 489, 608]); \
           print(result['llm_description'])"

# 4. å¯è§†åŒ–éªŒè¯
python visualizations/skeleton_extractor/vis_mars_recon_tokens.py --split test --index 1

# 5. æ‰¹é‡å¤„ç†
python llm_tools/batch_process_all.py
# é€‰æ‹©: 1 (100æ ·æœ¬æµ‹è¯•)
```

---
```



**å†…å­˜ä¼˜åŒ–ç‰¹æ€§:**
- âœ… æ‰¹å¤§å°ä¼˜åŒ–: 4 (é…åˆæ¢¯åº¦ç´¯ç§¯=2ï¼Œç­‰æ•ˆæ‰¹å¤§å°=8)
- âœ… åˆ†ç»„é‡æ„æŸå¤±: å¯¹æ¯ä¸ªè¯­ä¹‰ç»„å•ç‹¬è®¡ç®—æŸå¤±
- âœ… å…³èŠ‚æƒé‡ä¼˜åŒ–: å¤´éƒ¨ã€æ‰‹éƒ¨ã€è„šéƒ¨å…³èŠ‚æƒé‡Ã—2
- âœ… GPUå†…å­˜ç®¡ç†: è‡ªåŠ¨å†…å­˜æ¸…ç†å’Œä¼˜åŒ–åˆ†é…
- âœ… æ•°æ®åŠ è½½ä¼˜åŒ–: 2ä¸ªworkerè¿›ç¨‹ï¼Œå‡å°‘å†…å­˜å ç”¨

### Supported Datasets

- **NTU RGB+D**: Human action recognition dataset with skeleton data
- **MARS**: Multi-modal action recognition dataset
- **MMFI**: Multi-modal fitness dataset

### Configuration

Model configurations are stored in the `cfgs/` directory:
- `cfgs/NTU_models/` - NTU RGB+D dataset configurations
- `cfgs/MARS_models/` - MARS dataset configurations  
- `cfgs/MMFI_models/` - MMFI dataset configurations

## Project Structure

```
CRSkeleton/
â”œâ”€â”€ main.py                 # Main training script
â”œâ”€â”€ models/                 # Model implementations
â”‚   â”œâ”€â”€ GCNSkeletonTokenizer.py
â”‚   â”œâ”€â”€ Tokenizer.py
â”‚   â””â”€â”€ dvae.py
â”œâ”€â”€ datasets/              # Dataset implementations
â”œâ”€â”€ cfgs/                  # Configuration files
â”œâ”€â”€ tools/                 # Training utilities
â””â”€â”€ utils/                 # Common utilities
```

## Models

### GCNSkeletonTokenizer
- Graph Convolutional Network for skeleton feature extraction
- Tokenization of skeleton sequences
- Integration with DVAE for reconstruction

### DVAE (Discrete Variational Autoencoder)
- Discrete latent space representation
- Reconstruction loss optimization
- KL divergence regularization

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Based on PointNet++ PyTorch implementation
- Inspired by BERT tokenization mechanisms for skeleton data

